\documentclass[a4paper,9pt,journal]{IEEEtran}
\usepackage{graphicx} \usepackage[cmex10]{amsmath}
\usepackage{amssymb} \usepackage{fancybox} \usepackage{alltt}
\usepackage{soul} \usepackage{color} \usepackage{verbatim}
\usepackage{xcolor} \usepackage{colortbl,hhline}
\usepackage[ruled,vlined]{algorithm2e} \usepackage{framed}
\usepackage{amsthm} \usepackage{fancyref}
\usepackage{amsmath,amsfonts,amssymb, amsthm} \usepackage{textcomp}

\newtheorem{remark}{Remark}

\def \lb {{\langle}} \def \rb {{\rangle}}
\newcommand{\fro}[1]{\|#1\|_2}
\newcommand{\theHalgorithm}{\arabic{algorithm}}

\newcommand{\argmin}{\mathop{\mathrm{argmin}}}

\usepackage{hyperref}


\newtheorem{theorem}{Theorem} \newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}


\newcommand{\prox}{\textrm{pr ox} } \newcommand{\grad}{\textrm{grad} }
\newcommand{\dive}{\textrm{div} }

\pagenumbering{gobble}

\begin{document}
\onecolumn
\title{A fast primal-dual algorithm for computing Nash equilibria and best response strategies in two-person zero-sum sequential games}


\author{\IEEEauthorblockN{Elvis D. DOHMATOB}}


\maketitle

\begin{abstract}
% LESS THAN 200 WORDS !!!!!
% 
% While medical imaging typically provides massive amounts of
% data, the extraction of relevant information in a given
% applicative context remains a difficult challenge.
% XXX : don't call it SPM but just "predictive regions or predictive
% maps"
In this manuscript, we consider the problem of computing a best response against an opponent's realization plan in two-person sequential games.
The proposed algorithm for solving the corresponding contrained convex-optimization problem, derives from the primal-dual scheme of A. Chambolle and T. Pock.
Our algorithm is simple: all resolvent operators can be effectively computed in closed-form, using only elementary algebraic operations.
%%  and is orders of magnitude more efficient than state-of-the-art algorithms like those based on Linear Programming, Interior-Point methods,
%% and more recently, the Nesterov Excessive Gap Technique.
% By way of example, we conclude by exhibiting results on Texas Hold'em Poker.
\end{abstract}


\begin{IEEEkeywords}
  game theory; two-person sequential game; Nash equilibria; best response; convex-optimization; contraint; primal-dual scheme
\end{IEEEkeywords}

\section{Introduction}
%\label{sec:intro}
\subsection{Notation and Terminology}
To begin, let us introduce some technical notation and terminology we will be using in this paper. The reader should lookup any standard textbook
(for example \cite{boyd2004}) on convex optimization for a tutorial introduction to these notions. Viz,
\begin{itemize}
\item $\mathcal{P}(S)$: \quad set of all the subsets of $S$;
\item $\mathcal{P}_k(S)$: \quad set of all the subsets of $S$ which have exactly $k$ elements;
\item $\mathbb{R}^{m \times n}$: \quad space of all $m$-by-$p$ real matrices;
\item $E^{-1}(U)$: \quad pre-image of $U \subset \mathbb{R}^n$ under a matrix $E \in \mathbb{R}^{p,n}$,
namely the set $\{x \in \mathbb{R}^n\text{ }| \text{ }Ex \in U\}$;
\item $A^T$: \quad transpose of a matrix $A$;
\item $\begin{bmatrix}A\\B\end{bmatrix}$: \quad vertical stacking of two matrices $A$ and $B$;
\item $v_j$: \quad $j$th component of  a vector $v$;
\item $u^Tv$: \quad dot product of two vectors $u$ and $v$;
\item $\mathbb{R}^n_+$: \quad the $n$-dimensional nonnegative orthant;
\item $(x)_+$: \quad component-wise maximum of a vector $x$ and 0;
\item $i_C$: \quad indicator function of a convex set $C$;
\item $\Pi_C$: \quad euclidean projector onto a convex set $C$;
\item $\|K\|_2$: \quad matrix 2-norm of a matrix $K$;
\item \textit{l.s.c.p.c}: \quad acronym for adjective \textit{lower semi-continuous proper convex};
\item $f^*$: \quad Fenchel transform (a.k.a convex conjugate) of a \textit{l.s.c.p.c} function $f$;
\item $(1 + \sigma \partial f)^{-1}$: resolvent (a.k.a proximal) operator of a \textit{l.s.c.p.c} function $f$, for a given stepsize $\sigma > 0$
\end{itemize}

\subsection{Generating the Texas Hold'em Poker game tree}
Let $a := (a_1, a_2, a_3, a_4) \in 
\mathbb{R}\times\mathbb{R}\times\mathbb{R}^2\times\mathbb{R}^2$ hold the accounting info, where:
\begin{itemize}
\item $a_1\in\mathbb{R}$ is the running bet size,
\item $a_2\in\mathbb{R}$ is the running total amount in the pot,
\item $a_3\in\mathbb{R}^2$ is a vector showing what each player has put into the pot sofar, and
\item $a_4\in\mathbb{R}^2$ is a vector showing running capital of each player.
\end{itemize}
Let $ok(a, L)$ be a flag which is true iff the bet size $a_1$ has not exceeded the limit $L$ and each player's running credit is nonnegative.
For any round $t\in\mathbb{N}$, let $p(t)$ be the player to begin and $\Sigma(t)$ be the set of all signals that can be emitted by the chance player.
\definition{
A signal is simply any part of the information needed at shutdown to score the player's hands.
}
\remark{
An emitted signal can be fully observable (for example, community cards), or only partially observable (for example when private / hole / pocket cards are delt, players can only see their own hole cards given to them; they can't see another player's hole cards).
}

\begin{equation}
  \gamma(t, T, a, L) = \begin{cases} 
    \mathcal{P}_1(\Sigma(t)), &\mbox{if } (t < T) \land ok(a, L) \land (p(t) = 0);\\
            {\{\textbf{F}_{p(t)}\} \cup \textbf{C}_{p(t)}\gamma(t + 1, T, a, L) \cup \textbf{K}_{p(t)}\lambda(t, T, g(a, \textbf{K}_{p(t)}), L)},&\mbox{if } (t < T) \land ok(a, L) \land (p(t) > 0);\\
            \emptyset, &\mbox{if } t \ge T \lor \neg ok(a, L) .\end{cases}
\end{equation}
where the auxiliary function $\lambda$ is defined by:
\begin{equation}
  \left.
  \begin{aligned}
    \lambda(t, T, a, L) := \cup_{n=0}^\infty\alpha_1^{(n)}(t, T, a, L) \cup \cup_{n=0}^\infty\alpha_2^{(n)}(t, T, a, L)\\
    \alpha_1^{(n)}(t, T, a, L) := (\textbf{R}_{p(t)'}\textbf{R}_{p(t)})^n\mathcal{P}_1(\{\textbf{F}_{p(t)'}, \textbf{K}_{p(t)'}\})\gamma(t + 1, T, g(a, (\textbf{R}_{p(t)'}\textbf{R}_{p(t)})^n\mathcal{P}_1(\{\textbf{F}_{p(t)'}, \textbf{K}_{p(t)'}\})), L)\\
    \alpha_2^{(n)}(t, T, a, L) := (\textbf{R}_{p(t)'}\textbf{R}_{p(t)})^n\textbf{R}_{p(t)'}\mathcal{P}_1(\{\textbf{F}_{p(t)}, \textbf{K}_{p(t)}\})\gamma(t + 1, T, g(a, (\textbf{R}_{p(t)'}\textbf{R}_{p(t)})^n\textbf{R}_{p(t)'}\mathcal{P}_1(\{\textbf{F}_{p(t)}, \textbf{K}_{p(t)}\})), L)
    %% \lambda_{1}(t, T, a, L) := \cup_{n=0}^\infty\alpha_1^{(n)}(t, T, a, L)\\
    %% \lambda_{2}(t, T, a) := \cup_{n=0}^\infty\\
    \end{aligned}
  \right\}
\end{equation}

\subsection{Statement of the problem}
Consider a two-person sequential game\footnote{In a sequential game, players take turns in play, one after the other,
as opposed to simultaneous play.} in \textit{sequential-form} (See for example, \cite{von1996efficient}
and \cite{koller1996efficient} 
for theory on sequential-form representation), and let $A \in \mathbb{R}^{m,n}$ be our payoff matrix.
We will be referring to the other player as ``the opponent''. We are interested in the problem of
finding a best response strategy $x^* \in \mathbb{R}_{+}^n \cap E^{-1}(\{e\})$, given a fixed
behavioral strategy $y_0$ for the opponent, where $E$ is a sparse $p$-by-$n$ matrix whose
entries are $-1$, $0$, or $+1$, and $(1, 0, 0, ..., 0) =: e \in \mathbb{R}^p$. Recall that $E$
and $e$ encode linear constraints on our ``admissible'' realization plans\footnote{In games
in sequential form, the terms ``strategy'' and ``realization plan'' mean thesame thing.} $x$,
in the sequential form representation of the game. In the language of convex-optimization,
one can readily give the following saddle-point formulation for this problem. Viz,

\begin{equation}
  \underset{x \in \mathbb{R}_{+}^n \cap E^{-1}(\{e\})}{min}\text{ }-y_0^TAx
  \label{eq:opt_pb}
\end{equation}

\begin{definition}
A solution $x^*$ to problem \eqref{eq:opt_pb} is called a \textit{best response} strategy against
the opponent's fixed strategy $y_0$.
\end{definition}

\begin{remark}
Of course $y_0$ is not necessarily an optimal strategy for the opponent. In case it is, the pair $(x^*, y_0)$
is a Nash equilibrium for the game.
\end{remark}

\begin{remark}
  In practice, $A$, $E$, and $F$ are very sparse.
%% : $A$ will be sparse because a concrete sequential game will
%% typically have very few\footnote{Few, relative to the size of the game tree.} leafs, and only a few
%% combinations of sequences of moves of the players, will actually lead to a leaf (i.e. end the game);
%% $E$ and $F$ will be sparse because the kinks of possible sequences of moves of each player will
%% zig-zag between only a limited number of the player's information sets so that a move at an information set will
%% rarely\footnote{Relative to the number of information sets for the player.}  extend another information set.
This sparsity should be thoroughly exploited\footnote{For example when
multiplying vectors with these matrices.} by a solver for problem \eqref{eq:opt_pb}.
\end{remark}

In section \ref{sec:related_work}, we give a brief overview of existing methods for solving \eqref{eq:opt_pb}.
We elaborate our proposed algorithm in section \ref{sec:algo}.

\section{Related work}
\label{sec:related_work}

Pending...

\section{The proposed algorithm}
\label{sec:algo}
In this section we present the algorithm which is the purpose of this paper, namely an algorithm
for solving \eqref{eq:opt_pb}. Our algorithm (Alg.\ref{Tab:algo}) is a use-case of
the generic primal-dual algorithm of A. Chambolle and T. Pock, namely Algorithm 1 of \cite{chambolle2010}.

\subsection{Derivation of the algorithm}
First observe that (1) can be re-written in the form:
\begin{equation}
  \underset{x \in \mathbb{R}^n}{min}\text{ }{f(-Ax) + g(x)}
\end{equation}
where:\\
\begin{equation}
  \left.
  \begin{aligned}
    g := i_{E^{-1}(\{e\})} + i_{\mathbb{R}_{+}^m}\\
    f: z \mapsto y_0^Tz
    \end{aligned}
  \right\}
\end{equation}

Finally, the primal-dual formulation of this problem (which can be easily obtained using
\textit{Fenchel-Rockafellar duality}, for example) is:
\begin{equation}
  \underset{x \in \mathbb{R}^n}{min}\text{ }\underset{y \in \mathbb{R}^m}{max}\text{ }{y^T(-A)x_0 + g(x) - f^*(y)}
\end{equation}

Now, let's observe that $i_{E^{-1}(\{e\})}(x) = \underset{\zeta \in \mathbb{R}^p}{max}\text{ }\zeta^T(e - Ex)$, and so one can re-write (2) as:
\begin{equation}
  \underset{x \in \mathbb{R}^n}{min}\text{ }\underset{y \in \mathbb{R}^m, \zeta \in \mathbb{R}^p}{max}\text{ }
  \begin{bmatrix}y\\\zeta\end{bmatrix}^TKx + G(x) - F^*(y, \zeta)
  \label{eq:pd_opt}
\end{equation}
where we've defined:
\begin{equation}
  \left.
  \begin{aligned}
    K := -\begin{bmatrix}A\\E\end{bmatrix}\\
    G := g - i_{E^{-1}(\{b\})} = i_{\mathbb{R}_{+}^n}\\
    F^*: (y, \zeta) \mapsto (f^*(y) - \zeta^Te) = (i_{\{y_0\}}(y) - e^T\zeta)
  \end{aligned}
  \right\}
\end{equation}

Furthermore, one easily checks that $F^*$ and $G$ are \textit{l.s.c.p.c} with resolvent
(a.k.a \textit{proximity}) operators given by the simple formulae:
\begin{equation}
  \left.
  \begin{aligned}
    (1 + \tau \partial G)^{-1} = \Pi_{\mathbb{R}_+^n}: x \mapsto (x)_+\\
    (1 + \sigma \partial F^*)^{-1}: (y, \zeta) \mapsto (y_0, \zeta + \sigma e)
  \end{aligned}
  \right\}
\end{equation}

Using these ingredients, we derive the primal-dual algorithm given in Alg.\ref{Tab:algo}, 
for solving \eqref{eq:pd_opt}, and thus \eqref{eq:opt_pb}.

\begin{remark}
Equation \eqref{eq:pd_opt} is in the form of equation (2) in \cite{chambolle2010} if we take $X := \mathbb{R}^n$ and
$Y := \mathbb{R}^m \times \mathbb{R}^p$.
\end{remark}

\begin{remark}
Neither $G$ nor $F^*$ is strongly convex and so Alg.\ref{Tab:algo} cannot be accelerated in the sense of algorithm 39 of \cite{chambolle2010}.
\end{remark}

\begin{algorithm}[htb]
  \caption{Primal-dual algorithm for computing best response against opponent's fixed realization plan $y_0$}
  \textbf{Given} Tolerance $\epsilon > 0$.\\
  \textbf{Initialize} $\tilde{x^{(0)}} = x^{(0)} \in \mathbb{R}^n$; $\zeta^{(0)} \in \mathbb{R}^{q}$;
  $\tau, \sigma > 0 \text{ s.t. }\tau\sigma \|K\|_2^2 < 1$; $k = 0$.\\
  \textbf{Precompute} $\eta_0 \leftarrow \tau A^Ty_0$\\
  \Repeat{
    $\frac{\|x^{(k+1)} - x^{(k)}\|^2_2}{2\tau} + \frac{\|\zeta^{(k+1)} - \zeta^{(k)}\|^2_2}{2\sigma} < \epsilon$}{
    \begin{eqnarray*}
      \zeta^{(k+1)} &\leftarrow& \zeta^{(k)} - \sigma \bigl(e - E\tilde{x}^{(k)}\bigr)\\
      x^{(k+1)} &\leftarrow& \bigl(x^{(k)} + \eta_0 + E^T\zeta^{(k+1)}\bigr)_+\\
      \tilde{x}^{(k+1)} &\leftarrow& 2x^{(k+1)} - x^{(k)}\\
      k &\leftarrow& k + 1
    \end{eqnarray*}
  } \Return $x^{(k)}$, $-y_0^TAx^{(k)}$
  \label{Tab:algo}
\end{algorithm}

\subsection{Convergence analysis of the algorithm}
Pending...

\begin{remark}
The derivation above reveals that in equation \eqref{eq:opt_pb} above, if the constraint ``$x \ge 0$'' is replaced by
a constraint ``$x \in C$'' (thus obtaining a new problem) where $C$ is a convex set
%% onto which euclidean projections
%% can be easily computed (for example, a probability simplex)
, then we simply need to replace the operator ``$(.)_+$''
with ``$\Pi_C$'' in the equations to obtain a corresponding algorithm. Of course, this is because $i_C^* = \Pi_C$.
\end{remark}

\medskip \noindent
\textbf{Acknowledgments:}
Pending...

% ==========
% = biblio =
% ==========
% {\small
\bibliographystyle{IEEEtran} \bibliography{IEEEabrv,bib_tv.bib,agt.bib}
\end{document}




%
%


