\documentclass[a4paper,9pt,journal]{IEEEtran}
\usepackage{graphicx}
\usepackage[cmex10]{amsmath}
\usepackage{amssymb} \usepackage{fancybox} \usepackage{alltt}
\usepackage{soul} \usepackage{color} \usepackage{verbatim}
\usepackage{xcolor} \usepackage{colortbl,hhline}
\usepackage[ruled,vlined]{algorithm2e} \usepackage{framed}
\usepackage{amsthm} \usepackage{fancyref}
\usepackage{amsmath,amsfonts,amssymb, amsthm} \usepackage{textcomp}

\newtheorem{remark}{Remark}

\def \lb {{\langle}} \def \rb {{\rangle}}
\newcommand{\fro}[1]{\|#1\|_2}
\newcommand{\theHalgorithm}{\arabic{algorithm}}

\newcommand{\argmin}{\mathop{\mathrm{argmin}}}

\usepackage{hyperref}


\newtheorem{theorem}{Theorem} \newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}


\newcommand{\prox}{\textrm{pr ox} } \newcommand{\grad}{\textrm{grad} }
\newcommand{\dive}{\textrm{div} }

\pagenumbering{gobble}

\begin{document}
\onecolumn
\title{A fast and simple primal-dual algorithm for computing Nash equilibria in two-person zero-sum games}


\author{\IEEEauthorblockN{DOHMATOB Elvis}}


\maketitle

\begin{abstract}
% LESS THAN 200 WORDS !!!!!
% 
% While medical imaging typically provides massive amounts of
% data, the extraction of relevant information in a given
% applicative context remains a difficult challenge.
% XXX : don't call it SPM but just "predictive regions or predictive
% maps"
In this manuscript, we present a simple primal-dual algorithm for computing Nash equilibria and best reponse strategies in  sequential games with
imcomplete information and perfect recall. The proposed algorithm derives from the primal-dual scheme of A. Chambolle and T. Pock, applied to the
equilibrium and best response strategy problems in the sequence-form representation of the game. Our technique is to use a dualization
trick and unconstrain the saddle-point problem. All proximal operators in the resulting primal-dual algorithm are simple,
only involving nonnegative thresholding and translations.
The convergence and convergence rate of our algorithm derive explicitly from the general Chambolle-Pock primal-dual scheme.

%% In this manuscript, we consider the problem of computing a best response against an opponent's realization plan in two-person sequential games.
%% The proposed algorithm for solving the corresponding contrained convex-optimization problem, derives from the primal-dual scheme of A. Chambolle and T. Pock.
%% Our algorithm is simple: all resolvent operators can be effectively computed in closed-form, using only elementary algebraic operations.
%%  and is orders of magnitude more efficient than state-of-the-art algorithms like those based on Linear Programming, Interior-Point methods,
%% and more recently, the Nesterov Excessive Gap Technique.
% By way of example, we conclude by exhibiting results on Texas Hold'em Poker.
\end{abstract}


\begin{IEEEkeywords}
  game theory; Nash equilibrium; two-person zero-sum game; sequential game; imcomplete information; perfect recall; sequence-form representaion;
  best response strategy; convex-optimization; dualization; proximal operator; primal-dual algorithms
\end{IEEEkeywords}

\section{Introduction}
\label{sec:intro}

%% We will be needing the following notation: %%  The reader should lookup any standard textbook
%% %% (for example \cite{boyd2004}) on convex optimization for a tutorial introduction to these notions.
%% Viz,
%% \begin{itemize}
%% \item $\mathbb{R}^n$: $n$-dimensional real vector space;
%% \item $\mathbb{R}^{m \times n}$: \quad space of all $m$-by-$n$ real matrices;
%% \item $0_{m,n}$: $m$-by-$n$ matrix of zeros;
%% \item $(x)_+$: \quad component-wise maximum of a vector $x$ and 0;
%% \item $\mathbb{R}^n_+$: \quad $\{x \in \mathbb{R}^n|x = (x)_+\}$, the $n$-dimensional nonnegative orthant 
%% \item $i_C$: \quad indicator function of a convex set $C$;
%% % \item $\Pi_C$: \quad euclidean projector onto a convex set $C$;
%% \item $\|K\|_2$: \quad spectral norm of a matrix $K$
%% % \item $F^*$: the convex conjugate of a convex function $F$.
%% %% \item \textit{l.s.c.p.c}: \quad acronym for adjective \textit{lower semi-continuous proper convex};
%% %% \item $f^*$: \quad Fenchel transform (a.k.a convex conjugate) of a \textit{l.s.c.p.c} function $f$;
%% \end{itemize}

\subsection{Notation and Terminology}
\label{sec:notation}
We will need the following notations and definitions in the sequel. Given positive integers $m$ and $n$, $\mathbb{R}^{m \times n}$ denotes
the space of all $m$-by-$n$ real matrices. $0_{m,n}$ denotes the $m$-by-$n$ matrix of zeros and $1_{m,n}$ denotes the $m$-by-$n$ matrix of ones.
$\mathbb{R}^n_+$ := $\{x \in \mathbb{R}^n|x_j \ge 0 \text{ }  \forall j\}$ is the $n$-dimensional \textit{nonnegative orthant}.

For a vector $x \in \mathbb{R}^n$, $\|x\|$ denotes the $2$-\textit{norm} of $x$ defined by $\|x\| := \sqrt{x^Tx}$.
$(x)_+$ denotes its point-wise maximum with 0. Note that $(x)_+ \in \mathbb{R}^n_+$.
For example, $((-2, \pi))_+ = (max(-2, 0), max(\pi, 0)) = (0, \pi)$. The \textit{spectral norm} of a matrix $K$,
denoted $\|K\|$, is defined to be the largest \textit{singular value} of $K$, i.e the largest \textit{eigen-value} of $K^TK$ (or equivalently, of $KK^T$).

Given a \textit{convex subset} $C$ of $\mathbb{R}^n$, $i_C$ denotes its \textit{indicator function} defined by
$i_C(x) = 0$ if $x \in C$ and $i_C(x) = +\infty$ otherwise. Note that $i_{C \cap D} = i_C + i_D$. The \textit{euclidean projector} onto $C$, denoted $\Pi_C$ is the function
$\Pi: \mathbb{R}^n \mapsto C$, which maps a point $x \in \mathbb{R}^n$ to the (necessarily unique) point $\Pi_C(x)$ of $C$ which is closed to $x$. Precisely,
\begin{equation}
  \Pi_C(x) := \underset{c \in C}{argimin}\text{ }\|c - x\|^2
\end{equation}
For example, $\Pi_{\mathbb{R}^n_+}(x) = (x)_+, \forall x \in \mathbb{R}^n$.

Let $f : \mathbb{R}^n \rightarrow [0, +\infty]$ be a \textit{proper convex lower semi-continous function} (\textit{p.c.l.s.c} for short), and a positive real number $\tau$, the \textit{proximal operator} of $f$ of rank $\tau$,
denoted $\text{prox}_{\tau f}$ is the function which maps a point $x \in \mathbb{R}^n$ to the (necessarily unique) solution of the problem
\begin{equation}
  \underset{z \in \mathbb{R}^n}{argmin}\text{ }\frac{1}{2}\|z - x\|^2 + \tau f(z)
\end{equation}

It is easy to see that if $f$ is the indicator function of a convex set $C$, then $\text{prox}_{\tau f} = \Pi_C, \forall \tau > 0$. In this sense, proximal operators can be seen
as a generalization of euclidean projection operators.
\subsection{Statement of the problem}
We are interested in \textit{two-person zero-sum} games for which the \textit{Nash Equilibrium Problem (NEP)} can be formulated as
\begin{equation}
  \underset{y \in Q_2}{minimize}\text{ }\underset{x \in Q_1}{maximize}\text{ }{x^TAy}
  \label{eq:opt_pb}
\end{equation}

where \textit{feasibility sets} $Q_j$ have the form
\begin{equation}
  Q_j := \{z \in C_j|E_jz = e_j\},\text{ for some convex subset $C_j$ of a euclidean space $\mathbb{R}^{n_j}$, and some vector $e_j \in \mathbb{R}^{p_j}$}
\end{equation}
$Q_j$ is the \textit{strategy portfolio} for player $j$. $A$ is the \textit{payoff matrix} from player 1's perspective of the game: if player 1 players strategy
$x \in Q_1$ and player 2 plays strategy $y \in Q_2$ then player 1 gets $x^TAy$ units of money (and can be in fact negative!, in which case this represents a loss for player 1).
We will assume that the convex sets $C_j$ are simple enough so that the eucliean projectors $\Pi_{C_j}$ can be cheaply computed.
Typically, $C_j = \mathbb{R}^{p_j}_+$, and encodes a nonnegativity constraint; in this case, $\Pi_{C_j}(z) \equiv (z)_+$ as seen in subsection \ref{sec:notation}.
As usual, the ``minimize-maximize'' notation in problem \eqref{eq:opt_pb} means that a pair $(\hat{x}, \hat{y}) \in Q_1 \times Q_2$ is a solution iff
\begin{equation}
  x^TA\hat{y} \le x^TAy \le {\hat{x}}^TAy, \forall (x, y) \in Q_1 \times Q_2
\end{equation}
Such pairs $(\hat{x}, \hat{y})$ correspond to the Nash equilibria of the game, and ${\hat{x}}^TA\hat{y}$ is the \textit{value}
\footnote{This value is the same for every equilibrium pair $(\hat{x}, \hat{y})$.} of the game.

\subsection{Examples}
\label{subsec:example_games}
\begin{itemize}
\item[{\textit{(a)}}] \textit{Simultaneous two-person zero-sum games}\\
  Here, the NEP takes the form of problem \eqref{eq:opt_pb} with $p_j = 1$, $C_j = \mathbb{R}^{p_j}_+$, $E_j = 1_{1, n_j}$,
  and $e_j = 1$, so that $Q_j$ is simply the probabability $n_j$-simplex $\Delta_{n_j}$. Each point in $\Delta_{n_j}$ corresponds to a \textit{mixed-strategy} for player $j$,
and represents a randomization on their \textit{pure-strategies} (corresponding to the vertices of their propability simplex $\Delta_{n_j}$).
\item[{\textit{(b)}}] \textit{Two-person zero-sum sequential games with imcomplete information and perfect recall}\\
It is now known, thanks to the \textit{sequence-form representaion}, that the NEP for such games takes the form of problem \eqref{eq:opt_pb}

We recall that in the sequence-form representation of such games,  $E_j$ is a matrix whose
entries are $-1$, $0$, or $+1$, and $e_j := (1, 0, 0, ..., 0)$. We also recall that $E_1$ and $e_1$ (resp. $E_2$ and $e_2$)
encode linear constraints player 1's (resp. player 2's)  ``admissible'' \textit{realization plans} $x$ (resp. $y$).

As an illustration, the pair $(\hat{x}, \hat{y})$ given by
$\hat{x} = (1, .478, .522, .174, .826)$ and
$\hat{y} = (1, 1/2, 1/2)$ is a Nash equilibrium for the sequence-form game given by\\
$A = \left(\begin{array}{ccc}
0 & 0 & 0\\
0 & 0 & 0\\
0 & 1 & -1\\
0 & -2 & 4\\
1 & 0 & 0
\end{array}\right)$, $E_1 = \left(\begin{array}{ccccc}
  1 & 0 & 0 & 0 & 0\\
  -1 & 1 & 1 & 0 & 0\\
  -1 & 0 & 0 & 1 & 1
\end{array}\right)$,
$e_1 = (1, 0, 0)$, $E_2 = \left(\begin{array}{ccc}
  1 & 0 & 0\\
  -1 & 1 & 1
\end{array}\right)$, and $e_2 = (1, 0)$.
\end{itemize}


\begin{remark}
  At least for sequential games, the matrices $A$, $E_1$, and $E_2$ are very large (can have upto billions of rows and columns) but very sparse too.
%% : $A$ will be sparse because a concrete sequential game will
%% typically have very few\footnote{Few, relative to the size of the game tree.} leafs, and only a few
%% combinations of sequences of moves of the players, will actually lead to a leaf (i.e. end the game);
%% $E$ and $F$ will be sparse because the kinks of possible sequences of moves of each player will
%% zig-zag between only a limited number of the player's information sets so that a move at an information set will
%% rarely\footnote{Relative to the number of information sets for the player.}  extend another information set.
This sparsity should be thoroughly exploited by a solver for problem \eqref{eq:opt_pb}.
\end{remark}

%% In section \ref{sec:related_work}, we give a brief overview of existing methods for solving \eqref{eq:opt_pb}.
%% We elaborate our proposed algorithm in section \ref{sec:algo}.

%% \section{Related work}
%% \label{sec:related_work}

%% Pending...

\section{The proposed algorithm}
We preprose to solve problem \eqref{eq:opt_pb} using the primal-dual scheme of A. Chambolle and T. Pock.
Though this scheme has recently gained considerable popularity in the signal processing community, to the best of our knowledge,
this is the first time it is being applied to compute Nash equilibria.

We now detail the proposed algorithm for solving the saddle-point problem \eqref{eq:opt_pb}. The convergence and convergence rate
of our algorithm derive explicitly from the general Chambolle-Pock primal-dual scheme.

%% \label{sec:algo}
%% In this section we present the algorithm which is the purpose of this paper, namely an algorithm
%% for solving \eqref{eq:opt_pb}. Our algorithm (Alg.\ref{Tab:algo}) is a use-case of
%% the generic primal-dual algorithm of A. Chambolle and T. Pock, namely Algorithm 1 of \cite{chambolle2010}.

\subsection{Derivation of the algorithm}
Observe that $\forall (x, y) \in \mathbb{R}^{n_1} \times \mathbb{R}^{n_2}$, we have
\begin{equation}
  \left .
  \begin{split}
    -i_{Q_1}(x) &= -i_{C_1}(x) + \underset{v \in \mathbb{R}^{p_1}}{min}\text{}{v^T(e_1 - E_1x)}\\
  i_{Q_2}(y) &= i_{C_2}(y) + \underset{u \in \mathbb{R}^{p_2}}{max}\text{}{u^T(E_2y - e_2)}
  \end{split}
  \right\}
\end{equation}
and so problem \eqref{eq:opt_pb} can be re-written in the unconstrained form

\begin{equation}
  \underset{y \in \mathbb{R}^{n_2}, v\in \mathbb{R}^{p_1}}{minimize}\text{ }\underset{x \in \mathbb{R}^{n_1}, u \in \mathbb{R}^{p_2}}{maximize}
           {\begin{bmatrix}x\\u\end{bmatrix}^TK\begin{bmatrix}y\\v\end{bmatrix} + G(y, v) - F(x, u)}
  \label{eq:my_opt_pb}
\end{equation}

where $v \in \mathbb{R}^{p_1}$ and $u \in \mathbb{R}^{p_2}$ are auxiliary dual variables and 
\begin{equation}
  \left .
  \begin{split}
    K :=
    \left[
      \begin{array}{c|c}
        A & -E_1^T \\ \hline
        E_2 & 0_{p_2, p_1}
      \end{array}
      \right] \in \mathbb{R}^{(n_1 + p_2) \times (n_2 + p_1)} \\
    %%\begin{bmatrix}A \text{ } E_1^T\\ E_2 \text{ } 0\end{bmatrix} \in \mathbb{R}^{(n_2 + p_1) \times (n_1 + p_2)}\\
      G: \mathbb{R}^{n_2} \times \mathbb{R}^{p_1} \rightarrow [0, +\infty], (y, v) \mapsto i_{C_2}(y) + e_1^Tv\\
      F: \mathbb{R}^{n_1} \times \mathbb{R}^{p_2} \rightarrow [0, +\infty], (x, u) \mapsto i_{C_1}(x) + e_2^Tu
  \end{split}
  \right\}
  \label{eq:unconstrained_pb}
\end{equation}

It is clear that $G$ and $F$ are \textit{p.c.l.s.c} and a straightforward computation reveals that their proximal operators are given by
\begin{equation}
  \left .
  \begin{split}
    \text{prox}_{\tau G} : \mathbb{R}^{n_2} \times \mathbb{R}^{p_1} &\rightarrow \mathbb{R}^{n_2} \times \mathbb{R}^{p_1}\\
    (y, v) &\mapsto (\Pi_{C_2}(y), v - \tau e_1)\\
  \end{split}
  \right\}
\end{equation}

and
\begin{equation}
  \left .
  \begin{split}
    \text{prox}_{\sigma F}: \mathbb{R}^{n_1} \times \mathbb{R}^{p_2} &\rightarrow \mathbb{R}^{n_1} \times \mathbb{R}^{p_2}\\
    (x, u) &\mapsto (\Pi_{C_1}(x), u - \sigma e_2)
  \end{split}
  \right\}
\end{equation}

Putting everything together, we obtain Algorithm \ref{Tab:algo}.

\begin{algorithm}[htb]
  \caption{Primal-dual algorithm so solving the saddle-point problem \eqref{eq:opt_pb}}
  \textbf{require}
  \begin{itemize}
    \item the specification of a game $(A, E_1, E_2, e_1, e_2, C_1, C_2)$, where $A \in \mathbb{R}^{n_1 \times n_2}$,
  $E_1 \in \mathbb{R}^{p_1 \times n_1}$, $E_2 \in \mathbb{R}^{p_2 \times n_2}$, $e_1 \in \mathbb{R}^{p_1}$, $e_2 \in \mathbb{R}^{p_2}$, $C_j$ is a convex subset of $\mathbb{R}^{n_j}$;
      \item a tolerance level $\epsilon > 0$
  \end{itemize}
  \textbf{precompute} $\|K\|^2$, where $K$ is constructed as in equations \eqref{eq:unconstrained_pb}. $\|K\|^2$ can be computed via a \textit{power iteration} on $K^TK$, for example.\\
  \textbf{initialize}
  $x^{(0)} \in \mathbb{R}^{n_1}$; $v \in \mathbb{R}^{p_1}$; $\tilde{y^{(0)}}, y^{(0)} \in \mathbb{R}^{n_2}$; $u^{(0)} \in \mathbb{R}^{p_2}$; 
  $\tau, \sigma > 0 \text{ s.t. }\tau\sigma \|K\|_2^2 < 1$ (for example take $\tau = \sigma = \frac{.99}{\|K\|}$); $k = 0$.\\
  \Repeat{$\frac{\|\Delta x^{(k)}\|^2 + \|\Delta v^{(k)}\|^2}{\sigma} + \frac{\|\Delta y^{(k)}\|^2 + \|\Delta u^{(k)}\|^2}{\tau} < \epsilon$}{
    \begin{eqnarray*}
      x^{(k+1)} &\leftarrow& \Pi_{C_1}\left(x^{(k)} + \tau \left(A\tilde{y}^{(k)} - E_1^T\tilde{v}^{(k)}\right)\right)\\
      u^{(k+1)} &\leftarrow& u^{(k)} + \tau \left(E_2\tilde{y}^{(k)} - e_2\right)\\
      y^{(k+1)} &\leftarrow& \Pi_{C_2}\left(y^{(k)} - \sigma \left(A^Tx^{(k + 1)} + E_2^Tu^{(k + 1)}\right)\right)\\
      v^{(k+1)} &\leftarrow& v^{(k)} - \sigma \left(e_1 - E_1x^{(k+1)}\right)\\
      \tilde{y}^{(k+1)} &\leftarrow& 2y^{(k+1)} - y^{(k)}\\
      \tilde{u}^{(k+1)} &\leftarrow& 2u^{(k+1)} - u^{(k)}\\
      k &\leftarrow& k + 1
    \end{eqnarray*}
  } \Return $x^{(k)}$, $y^{(k)}$
  \label{Tab:algo}
\end{algorithm}

\subsubsection{Special case: $C_j = \mathbb{R}^{n_j}_+$} As discussed in subsection \ref{subsec:example_games},
the NEP for two-person zero-sum simultaneous games and two-person zero-sum sequential games with imcomplete
information and perfect admits the formulation \eqref{eq:opt_pb}, with $C_j = \mathbb{R}^{n_j}_+$ (coding for nonnegativity constraints).
In such situations, $\Pi_{C_j}(z) \equiv (z)_+$ as already mentioned in \ref{sec:notation}, and Algorithm \ref{Tab:algo} reduces to the simpler Algorithm \ref{Tab:algo_simplified}.

\begin{algorithm}[htb]
  \caption{Primal-dual algorithm so solving the saddle-point problem \eqref{eq:opt_pb}, with nonnegativity constraints $C_j = \mathbb{R}^{n_j}_+$}
  \textbf{require}
  \begin{itemize}
    \item the specification of a game $(A, E_1, E_2, e_1, e_2)$, where $A \in \mathbb{R}^{n_1 \times n_2}$,
  $E_1 \in \mathbb{R}^{p_1 \times n_1}$, $E_2 \in \mathbb{R}^{p_2 \times n_2}$, $e_1 \in \mathbb{R}^{p_1}$, $e_2 \in \mathbb{R}^{p_2}$;
      \item a tolerance level $\epsilon > 0$
  \end{itemize}
  \textbf{precompute} $\|K\|^2$, where $K$ is constructed as in equations \eqref{eq:unconstrained_pb}. $\|K\|^2$ can be computed via a \textit{power iteration} on $K^TK$, for example.\\
  \textbf{initialize}
  $x^{(0)} \in \mathbb{R}^{n_1}$; $v \in \mathbb{R}^{p_1}$; $\tilde{y^{(0)}}, y^{(0)} \in \mathbb{R}^{n_2}$; $u^{(0)} \in \mathbb{R}^{p_2}$; 
  $\tau, \sigma > 0 \text{ s.t. }\tau\sigma \|K\|_2^2 < 1$ (for example take $\tau = \sigma = \frac{.99}{\|K\|}$); $k = 0$.\\
  \Repeat{$\frac{\|\Delta x^{(k)}\|^2 + \|\Delta v^{(k)}\|^2}{\sigma} + \frac{\|\Delta y^{(k)}\|^2 + \|\Delta u^{(k)}\|^2}{\tau} < \epsilon$}{
    \begin{eqnarray*}
      x^{(k+1)} &\leftarrow& \left(x^{(k)} + \tau \left(A\tilde{y}^{(k)} - E_1^T\tilde{v}^{(k)}\right)\right)_+\\
      u^{(k+1)} &\leftarrow& u^{(k)} + \tau \left(E_2\tilde{y}^{(k)} - e_2\right)\\
      y^{(k+1)} &\leftarrow& \left(y^{(k)} - \sigma \left(A^Tx^{(k + 1)} + E_2^Tu^{(k + 1)}\right)\right)_+\\
      v^{(k+1)} &\leftarrow& v^{(k)} - \sigma \left(e_1 - E_1x^{(k+1)}\right)\\
      \tilde{y}^{(k+1)} &\leftarrow& 2y^{(k+1)} - y^{(k)}\\
      \tilde{u}^{(k+1)} &\leftarrow& 2u^{(k+1)} - u^{(k)}\\
      k &\leftarrow& k + 1
    \end{eqnarray*}
  } \Return $x^{(k)}$, $y^{(k)}$
  \label{Tab:algo_simplified}
\end{algorithm}


\section{Application to Poker}
\subsection{Kuhn Poker}
The Kuhn 3-card Poker has sequence-form specification given by (not showing zero entries)\\
$A = \left(\begin{array}{ccccccccccccc}
  &   &   &   &   &   &   &   &   &   &   &   &  \\
  &   &   &   &   &   &   & -1 / 6 &   &   &   & -1 / 6 &  \\
  &   &   &   &   &   &   &   & -1 / 6 &   &   &   & -1 / 6\\
  &   &   &   &   &   &   &   & -1 / 3 &   &   &   & -1 / 3\\
  &   &   &   &   & 1 / 6 & -1 / 3 &   &   & 1 / 6 & -1 / 3 &   &  \\
  &   &   & 1 / 6 &   &   &   &   &   &   &   & -1 / 6 &  \\
  &   &   &   & -1 / 6 &   &   &   &   &   &   &   & -1 / 6\\
  &   &   &   & 1 / 3 &   &   &   &   &   &   &   & -1 / 3\\
  & 1 / 6 & 1 / 3 &   &   &   &   &   &   & 1 / 6 & -1 / 3 &   &  \\
  &   &   & 1 / 6 &   &   &   & 1 / 6 &   &   &   &   &  \\
  &   &   &   & -1 / 6 &   &   &   & -1 / 6 &   &   &   &  \\
  &   &   &   & 1 / 3 &   &   &   & 1 / 3 &   &   &   &  \\
  & 1 / 6 & 1 / 3 &   &   & 1 / 6 & 1 / 3 &   &   &   &   &   &  
\end{array}\right)
 \in \mathbb{R}^{13 \times 13}$,\\
$E_1 = \left(\begin{array}{ccccccccccccc}
1 &   &   &   &   &   &   &   &   &   &   &   &  \\
-1 &   &   &   &   &   &   &   &   & 1 &   &   & 1\\
-1 & 1 &   &   & 1 &   &   &   &   &   &   &   &  \\
-1 &   &   &   &   & 1 &   &   & 1 &   &   &   &  \\
  & -1 & 1 & 1 &   &   &   &   &   &   &   &   &  \\
  &   &   &   &   & -1 & 1 & 1 &   &   &   &   &  \\
  &   &   &   &   &   &   &   &   & -1 & 1 & 1 &  
\end{array}\right)  \in \mathbb{R}^{7 \times 13}$, $e_1 = e_2 = (1, 0, 0, 0, 0, 0, 0) \in \mathbb{R}^7$,\\
$E_2 = \left(\begin{array}{ccccccccccccc}
1 &   &   &   &   &   &   &   &   &   &   &   &  \\
-1 &   &   &   &   &   &   & 1 & 1 &   &   &   &  \\
-1 &   &   &   &   &   &   &   &   & 1 & 1 &   &  \\
-1 &   &   &   &   & 1 & 1 &   &   &   &   &   &  \\
-1 &   &   &   &   &   &   &   &   &   &   & 1 & 1\\
-1 & 1 & 1 &   &   &   &   &   &   &   &   &   &  \\
-1 &   &   & 1 & 1 &   &   &   &   &   &   &   &  
\end{array}\right)  \in \mathbb{R}^{7 \times 13}$.\\
The pair $(\hat{x}, \hat{y}) \in \mathbb{R}^{13}_+ \times \mathbb{R}^{13}_+$ of realization plans given by $\hat{x} = (1, 0.759, 0.759, 0, 0.241, 1, 0.425, 0.575, 0, 0.275, 0, 0.275, 0.725)$ and\\
$\hat{y} = (1, 1, 0, 0.667, 0.333, 0.667, 0.333, 1, 0, 0, 1, 0, 1)$ is a Nash equlibrium for the game, computed using Algorithm  \ref{Tab:algo_simplified}. The convergence curve is shown in Fig \ref{Tab:conv_curves}. One easy checks that this equilibrium is feasible. Indeed,  $E_1\hat{x} - e_1 = (4.76 \times 10^{-5}, -1.91 \times 10^{-5}, 5.67 \times 10^{-5}, 8.23 \times 10^{-6}, 2.90 \times 10^{-5}, -8.62 \times 10^{-7}, -1.96 \times 10^{-5})$ and $E_2\hat{y} - e_2 = (-7.04 \times 10^{-7}, 2.27 \times 10^{-6}, -3.29 \times 10^{-6}, -1.50 \times 10^{-6}, 2.92 \times 10^{-6}, -4.97 \times 10^{-7}, -5.85 \times 10^{-7})$. Finally, $\hat{x}^TA\hat{y} = -0.055593685705289997$, which agrees to 4 d.p with the value of $-1 / 18$ computed analytically by Kuhn in his 1954 paper.

\begin{figure}
  \includegraphics[width=.5\linewidth]{Kuhn3112_NE.pdf}
  \includegraphics[width=.5\linewidth]{SimplifiedPoker_NE.pdf}
  \caption{Convergence curves of Algorithm \ref{Tab:algo_simplified} on simplified variants of Poker. \textbf{Left}: Kuhn Poker. \textbf{Right}: Another simplified Poker variant}.
  \label{Tab:conv_curves}
\end{figure}

%% \subsection{Convergence analysis of the algorithm}
%% Pending...

%% \begin{remark}
%% The derivation above reveals that in equation \eqref{eq:opt_pb} above, if the constraint ``$x \ge 0$'' is replaced by
%% a constraint ``$x \in C$'' (thus obtaining a new problem) where $C$ is a convex set
%% %% onto which euclidean projections
%% %% can be easily computed (for example, a probability simplex)
%% , then we simply need to replace the operator ``$(.)_+$''
%% with ``$\Pi_C$'' in the equations to obtain a corresponding algorithm. Of course, this is because $i_C^* = \Pi_C$.
%% \end{remark}

%% \medskip \noindent
%% \textbf{Acknowledgments:}
%% Pending...

% ==========
% = biblio =
% ==========
% {\small
\bibliographystyle{IEEEtran} \bibliography{IEEEabrv,bib_tv.bib,agt.bib}
\end{document}




%
%


